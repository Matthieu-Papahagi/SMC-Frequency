---
title: "M4R MCMC v3"
author: "Matthieu-Georges Papahagi"
date: "07/12/2021"
output:
  pdf_document: default
  html_document:
    codefont: ComputerModern
    mainfont: ComputerModern
    monofont: ComputerModern
    sansfont: ComputerModern
    theme: united
---

```{r setup, include=FALSE}
# set default to displaying neither code nor output
knitr::opts_chunk$set(echo = TRUE, include = TRUE, fig.align="center",fig.width=8, fig.height=4)
# theme_set(theme_minimal())
```

```{r, include=FALSE, echo = FALSE}
# packages

# aspect & extended functionality libraries
library(knitr)
library(tidyverse)
library(lemon)
library(png)
#library(docstring)

# plotting libraries
library(grid)
library(gridExtra)
library(ggplot2)
library(gghighlight)
library(plotly)
library(hrbrthemes)
# 3D plotting libraries
#library(rgl)
#library(plot3D)
#library(plot3Drgl)
#library(zoom)

# Statistics and TS libraries
library(MASS)
library(lme4)
library(TSA)
library(aTSA)
library(forecast)
library(goftest)
library(garma)
library(invgamma)

# Numerical analysis libraries
library(pracma)
require(numbers)
library(numDeriv)
library(inflection)
library(mosaicCalc)
library(nloptr)
library(MonteCarlo)
library(mcmc)

# latex libraries
#library(latex2exp)
#library(tinytex)

knit_print.data.frame <- lemon_print
```

-------------------------------------------------------

# 1. Introduction

In this preliminary markdown we model the SDF of a seasonally-persistent time series in the frequency domain, first using MLE, and then MCMC. This is largely an attempt to reproduce the results in McCoy and Stephens (2004). Subsequently, the intention is to use SMC instead of MCMC, and later address estimation issues, such as biases. The goal is to obtain accurate forecasts with confidence intervals for the time series. The steps are:

1. Choosing a seasonally-persistent time series and stationarising it.

2. Specifying a time series model (here GARMA(p,q,k)) for the de-trended data and determining the spectral density function (SDF). We aim to estimate the parameters of this SDF, so that we may get (via a bijection) the parameters of the time-domain representation, which can then be used for forecasting.

3. Constructing the Whittle-type loglikelihood based on this SDF (here several possibilities exist, so deciding which is best is the core of this part of the mathematical research). Already at this point, we could use MLE to estimate the parameters, which we do for comparison reasons; however, the focus is instead on using Bayesian inference through simulation of the posterior, first via MCMC, then via SMC.

4. Specifying a joint prior distribution for the frequency-domain parameters of the model and determining the posterior up to proportionality by multiplying this prior by the likelihood from the previous point. For simplicity, we can set independent uniform priors on each root parameter like in McCoy & Stephens (2004) and an Inverse Gamma prior on the innovations variance.

5. Simulating from the posterior distributions of the spectral-domain coefficients, using Metropolis-Hastings within Gibbs. This step will be later replaced with SMC.

6. Obtaining estimates and confidence intervals for the parameters based on their posterior distributions, transforming back to the time-domain representation, and forecasting the time series.

-------------------------------------------------------

# 2. Data

The dataset used is US monthly retail sales of electricity (in millions of kWh) for all sectors. The data ranges from January 2001 to August 2021 and has 248 entries. We will keep this time range as it has an even number of entries, which is helpful for computing the Fourier frequencies. The data was obtained from: [www.eia.gov/electricity](https://www.eia.gov/electricity/data/browser/#/topic/5?agg=0,1&geo=g&endsec=vg&linechart=ELEC.SALES.US-ALL.M~ELEC.SALES.US-RES.M~ELEC.SALES.US-COM.M~ELEC.SALES.US-IND.M&columnchart=ELEC.SALES.US-ALL.M~ELEC.SALES.US-RES.M~ELEC.SALES.US-COM.M~ELEC.SALES.US-IND.M&map=ELEC.SALES.US-ALL.M&freq=M&start=200101&end=202108&ctype=linechart&ltype=pin&rtype=s&pin=&rse=0&maptype=0)

## Importing the Data
```{r, include=TRUE}
# full dataset
# US_Electricity_Data = read.csv("~/Desktop/M4R/M4R Data/US Electricity Data/US_Electricity_Data.csv")
# #kable(US_Electricity_Data[c(1:5,244:248),],caption = "Snippet of the data - first and last 5 rows")
# 
# # Time series of interest
# time = US_Electricity_Data[[2]]
# x = US_Electricity_Data$all
```

```{r, include=TRUE, fig.width=12, fig.height=5}
# ## Plotting the original time series
# original_data_plot <- ggplot(US_Electricity_Data, aes(x = index, y = all)) + geom_line(na.rm=TRUE) + ggtitle("US Monthly Electricity Retail Sales (Jan-01 to Aug-21)") + xlab("Date") + ylab("Millions of kWh") + scale_x_continuous(breaks = seq(1, 249, by=48), labels = seq(2001,2021,by=4)) + theme_bw()
#   
# # Turn it interactive withp <- ggplotly(original_data_plot)
# original_data_plot
```

```{r, include=FALSE, echo = FALSE}
# save the plot
# png(file="/Users/mateipapahagi/Desktop/M4R/M4R Article+Figures/US_Electricity_Original.png", width=600, height=350)
# original_data_plot
# dev.off()
```

## Choosing and plotting a dataset

```{r}
x = x_holiday
plot(x,type="l")
plot(diff(x),type="l")
periodogram(x)
periodogram(diff(x))
```

## Differencing the time series to stationarise
```{r, include=TRUE, fig.width=6, fig.height=3}
y = diff(x)
# remove the last element of y to make it of even length
y=y[-length(y)]
mu = mean(y)
sigma_square = sd(y)^2
# cat(mu,sigma_square)

# plot(y, type="l", main="Differenced Time Series", ylab='', xlab='', frame.plot=TRUE)

# to remove axis labels xaxt='n', yaxt='n'
```

## Periodogram of the stationarised time series:
```{r, include=TRUE}
periodogram(y)
abline(v=0.168,col="red",lty=2)
abline(v=0.084,col="red",lty=2)
abline(v=0.252,col="red",lty=2)
abline(v=0.332,col="red",lty=2)
abline(v=0.416,col="red",lty=2)
```
We notice two clear peaks at frequencies of about 0.083 (=1/12) and 0.166 (1/6), corresponding to yearly and 6-month periods, as well as three other smaller peaks at higher frequencies.

## Calculating the Fourier frequencies
$$f_j=\frac{j}{N},\quad j\in{\{0,1,...,J=N/2\}}$$
```{r}
fourier_freqs <- function(y)
# returns the Fourier frequencies for a time series y
{
N=length(y)
# vector of Fourier frequencies
J=N/2
f=c()
for (j in 0:J) {f[j+1]<-j/N}
return(f)
}
```

-------------------------------------------------------

# 3. Parametrization, Periodogram, SDF, and Likelihood

The $\text{GARMA}(p,k,q)$ model is given by:

$$\Phi(B)\prod_{j=1}^k (1-2\lambda_jB+B^2)^{\delta_j}Y_t=\Theta(B)\epsilon_t$$
where 

$$\Phi(z)=\prod_{j=1}^p(1-\xi_{1j}z)$$

and

$$\Theta(z)=\prod_{j=1}^q(1-\xi_{2j}z)$$
are the $\text{AR}(p)$ and $\text{MA}(q)$ polynomials and $\xi_{rj}, \: r=1,2$ are the reciprocal roots of these polynomials. Therefore, we use a latent-structure parametrisation.

With the SDF of the $\text{GARMA}(p,k,q)$ process given by

$$
S_Y(f)=\sigma_\epsilon^2\frac{\prod_{j=1}^q\bigg|1-\xi_{2j}e^{2\pi i f} \bigg|^2}{\prod_{j=1}^p\bigg|1-\xi_{1j}e^{2\pi i f} \bigg|^2}\frac{1}{\prod_{j=1}^k[4\{\cos(2\pi f)-\lambda_j\}^2]^{\delta_j}}
$$

we write the $p=R_p+2C_p$ reciprocal AR roots and the $p=R_q+2C_q$ reciprocal MA roots as:

$$\xi_{1j}=\alpha_{1j}, \: j=1,...,R_p, \quad \text{and} \quad \xi_{1j}^{*\pm}=\alpha_{1j}^*e^{\pm2\pi i \omega^*_{rj}}, \: j=1,...,C_p$$

and

$$\xi_{2j}=\alpha_{2j}, \: j=1,...,R_q, \quad \text{and} \quad \xi_{2j}^{*\pm}=\alpha_{2j}^*e^{\pm2\pi i \omega^*_{2j}}, \: j=1,...,C_q$$

where

$$\alpha_{1i}\in{[0,1]}, i=1,...,R_p, \quad\alpha_{1i}^*\in{(0,1]}, i=1,...,C_p,$$

and 

$$\omega_{1i}=0, i=1,...,R_p, \quad \omega_{1i}^* \in{(0,1/2)}$$

and similarly for $\alpha_{2j}, j=1,...,R_q$, $\alpha_{2j}^*, j=1,...,C_q$, $\omega_{2j}=0, j=1,...,R_p$, and $\omega_{2j}^*=0, j=1,...,R_p$.


## Function to build complex conjugate AR and MA roots based on arguments and moduli.

```{r}
xi_builder <- function(alpha,omega)
# this function builds complex reciprocal roots xi 
# (or real roots) based on equal length vectors 
# alpha (modulus) and omega (argument).
  
# the input has the following constraints 
# for each component of alpha and omega: 
# 0<=alpha_i<1, 0<=omega_i<1/2, so the values 
# where omega=0 correspond to real roots.
  
# Finally, where omega_i>0, there is 
# an even number of equal omega_i and 
# similarly for the alphas 
# (i.e. the two complex conjugate roots 
# have the same absolute value of the argument 
# and the same modulus)
# So, for instance, we could have alpha=(1/6,1/4,1/3,1/2), 
# and correspondingly omega=(0,0,1/5,1/3)
# giving xi=(1/6,1/4,
# 1/3*e^1/5*2pi*i,1/3*e^-1/5*2pi*i,
# 1/2*e^1/3*2pi*i,1/2*e^-1/3*2pi*i)
{
  # firstly, sort alpha and omega
  alpha <- sort(alpha)
  omega <- sort(omega)
  # count the number of real roots (corresp to omega=0)
  # and the number of complex roots (omega!=0)
  R <- sum(omega == 0)
  C <- sum(omega != 0)
  # initialize xi
  xi=rep(0,R+2*C)
  j = 1
  for (i in 1:length(omega))
    {
     # real roots
      if (omega[i] == 0)
      {
        xi[j] = alpha[i]
        j = j+1
      }
      # complex conjugate roots
      else
      {
        xi[j] = alpha[i]*exp(2i*pi*omega[i])
        xi[j+1] = alpha[i]*exp(-2i*pi*omega[i])
        j = j+2
      }
   }
  return(xi)
}
# test:
alpha=c(1/3,1/6,1/4,1/2)
omega=c(1/5,0,1/3,0)
alpha=c(1/3,1/2)
omega=c(1/3,0)
xi_builder(alpha,omega)
```

## Periodogram
$$\hat{S}_p(f)=\Bigg|\sum_{t=1}^N(Y_t-\mu)e^{-2\pi i ft}\Bigg|^2$$
```{r}
# Build the periodogram
S_p <- function(f,y)
{ 
  mu <- mean(y)
  N <- length(y)
  summands <- c()
  for (t in 1:N) {summands[t]<-(y[t]-mu)*exp(-2i*pi*f*t)}
  return(1/N*Mod(sum(summands)))
}

S_p_vec <- Vectorize(S_p, vectorize.args = "f")
# test: 
# plot(f, S_p_vec(f,y), type = "h", lwd=1.5)
# abline(v=0.1666,col="red",lty=2)
# abline(v=0.084,col="red",lty=2)
# abline(v=0.252,col="red",lty=2)
# abline(v=0.332,col="red",lty=2)
# abline(v=0.416,col="red",lty=2)
plot(S_p_vec(f,y),type="h")
```

## Spectral density function (SDF)
$$
S_Y(f)=\sigma_\epsilon^2\frac{\prod_{j=1}^q\bigg|1-\xi_{2j}e^{2\pi i f} \bigg|^2}{\prod_{j=1}^p\bigg|1-\xi_{1j}e^{2\pi i f} \bigg|^2}\frac{1}{\prod_{j=1}^k[4\{\cos(2\pi f)-\lambda_j\}^2]^{\delta_j}}
$$
```{r}
S_Y <- function(f,alpha1,omega1,alpha2,omega2,
                lambda,delta,sigma_epsilon,p,q,k)
# alpha1 and omega1 have length Rp+Cp
# alpha2 and omega2 have length Rq+Cq
{
  # initialize the terms in the SDF
  MA_multiplicands <- AR_multiplicands <- G_multiplicands <- c()
  # build the complex reciprocal roots
  xi1 <- xi_builder(alpha1,omega1) # has length p=Rp+2*Cp
  xi2 <- xi_builder(alpha2,omega2) # has length q=Rq+2*Cq
  
   for (j in 1:q) {MA_multiplicands[j]<-1-xi2[j]*exp(2i*pi*f)}
  MA_factor <- prod(Mod(MA_multiplicands)^2)
  
   for (j in 1:p) {AR_multiplicands[j]<-1-xi1[j]*exp(2i*pi*f)}
  AR_factor <- prod(Mod(AR_multiplicands)^2)
  
   for (j in 1:k) {G_multiplicands[j]<-(4*(cos(2*pi*f)-lambda[j])^2)^delta[j]}
  G_factor <- prod(G_multiplicands)
  
  return(sigma_epsilon*MA_factor/AR_factor*1/G_factor)
}

S_Y_vec <- Vectorize(S_Y, vectorize.args = "f")
```

## Whittle-likelihood (master function)
$$
l(\eta|Z) = -\sum_{j=1}^J\bigg[\log\{S_Y(f_j)\}+\frac{Z_j}{S_Y(f_j)}\bigg]-\frac{1}{2}\bigg[\frac{Z_0}{S_Y(f_0)}+\frac{Z_J}{S_Y(f_J)}+\log\{Z_0 S_Y(f_0)\}+\log\{Z_J S_Y(f_J)\} \bigg]
$$
where $\eta=(\alpha_{11},\dots,\alpha_{1p},\omega_{11},\dots,\omega_{1p},\alpha_{21},\dots,\alpha_{2q},\omega_{21},\dots,\omega_{2q},\delta_{11},\dots,\delta_{1k},\lambda_{11},\dots,\lambda_{1k},p,q,k,\sigma_\epsilon^2)$ is the $2(p+q+k)+4$ vector of parameters and $Z=\big(Z_0=\hat{S}_p(f_0)\dots,Z_J=\hat{S}_p(f_J)\big)$ is the vector of periodogram values evaluated at the Fourier frequencies.
```{r}
W_l <- function(y,alpha1,omega1,alpha2,omega2,
                lambda,delta,sigma_epsilon,
                Rp,Cp,Rq,Cq,k)
{
# ! give J,f,Z as inputs, calculate outside
J <- length(y)/2
# Calculate the Fourier frequencies
f <- fourier_freqs(y)
# Evaluate the periodogram at the Fourier frequencies 
# (vector Z):
Z <- S_p_vec(f,y)
# Evaluate the SDF at the Fourier frequencies:
p <- Rp + 2*Cp
q <- Rq + 2*Cq
S_Y_f <- S_Y_vec(f,alpha1,omega1,alpha2,omega2,
                lambda,delta,sigma_epsilon,p,q,k)

# build the summands for the sum from j=1 to J-1
l_summands <- c()
for (j in 2:J-1)
{
  l_summands[j] <- log(S_Y_f[j]) + Z[j]/S_Y_f[j]
  # ! try to vectorize this
}

W_l <- -sum(l_summands)-1/2*(Z[1]/S_Y_f[1]+Z[J]/S_Y_f[J] +log(Z[1]*S_Y_f[1])+log(Z[J]*S_Y_f[J]))

return(W_l)
}
```

-------------------------------------------------------

# 4. Fixed-parameter MCMC

Here we specify a fixed number of real ($R_p$ and $R_q$) and complex conjugate roots ($C_p$ and $C_q$) for the $\text{AR}(p)$ and $\text{MA}(q)$ polynomials, respectively, where $R_p+2C_p=p$ and $R_q+2C_q=q$. For the real roots, the arguments $\omega$ are constrained to always be 0).

## Main function

Notes:

- The function doesn't work yet with one parameter 0

- The last argument of the function, "sigma_norm" is the variance of the M-H Gaussian proposal (Normal random walk), which is chosen to be the same for all parameters. A higher value means that the sample space is better explored, but more candidate values are rejected (lower acceptance probability). This is the tuning parameter.

```{r}
###############
# Define the function with input parameters: 
# nt = number of iterations; nburn = burn-in
# sigma_norm = variance of normal random walk
MCMC_v3 <- function(y,Rp,Cp,Rq,Cq,k,nt,nburn,sigma_norm=0.05)
{

# Read in the lower and upper bounds for the uniform priors for all parameters

# lower bounds for uniform priors 
   lb <- c(0, 0, # alpha1R and alpha1C
           0, 0, # omega1R and omega1C
           0, 0, # alpha2R and alpha2C
           0, 0, # omega2R and omega2C
          -1, 0, # lambda and delta
          0) # sigma_epsilon

# upper bounds for uniform priors
   ub <- c(1, 1, # alpha1R and alpha1C
           0, 1/2, # omega1R and omega1C
           1, 1, # alpha2R and alpha2C
           0, 1/2, # omega2R and omega2C
           1, 1/2, # lambda and delta
           100) # sigma_epsilon

# shape and rate parameters for sigma_epsilon (InvGamma)
sr <- c(3,5)

###############
# Set initial parameter values 

# set seed for reproducibility
set.seed(100) 

# polar components of AR(p) reciprocal roots
alpha1R <- runif(Rp,0,1)
alpha1C <- runif(Cp,0,1)
omega1R <- rep(0,Rp)
omega1C <- runif(Cp,0,1/2)

# polar components of MA(q) reciprocal roots
alpha2R <- runif(Rq,0,1)
alpha2C <- runif(Cq,0,1)
omega2R <- rep(0,Rq)
omega2C <- runif(Cq,0,1/2)

# Gegenbauer parameters
lambda <- runif(k,-1,1)
delta <- runif(k,0,1/2)
sigma_epsilon <- 1.5

# build list of parameters
param <- list(alpha1R, alpha1C, omega1R, omega1C,
              alpha2R, alpha2C, omega2R, omega2C,
              lambda, delta, sigma_epsilon)

nparam <- length(param) # number of sets of parameters in list (11)
 
# Calculate log-likelihood for initial state
f <- fourier_freqs(y)

alpha1 <- c(alpha1R, alpha1C)
omega1 <- c(omega1R, omega1C)

alpha2 <- c(alpha2R, alpha2C)
omega2 <- c(omega2R, omega2C)

likhood <- W_l(y,alpha1,omega1,alpha2,omega2,
              lambda,delta,sigma_epsilon,Rp,Cp,Rq,Cq,k)

# Define itns - list of lists of vectors of parameters for each iteration 
# to store sample from posterior distribution:
itns <- vector(mode='list', length=nt)
# output - vector for parameter values and associated log-likelihood (last entry):
output <- dim(nparam+1)

# MCMC updates - MH algorithm - cycle through each iteration: 
for (t in 1:nt)
{
# Update the parameters in the model using function "updateparam":

output <- updateparam(nparam,param,y,likhood,
                    lb,ub,sr,sigma_norm,Rp,Cp,Rq,Cq,k)

# Set parameter values and log-likelihood to be the output from the MH step:
param <- output[1:nparam]
likhood <- output[[nparam+1]]

itns[[t]] <- param
}

###############
# Post-processing
# Remove the burn-in from the simulations and calculate
# the mean and standard deviation of the parameters
subitns <- itns[(nburn+1):nt] # has length nt-nburn

# Extract the list of iterations for each vector of parameters
# find a better way than this for, which is O(11xnt) time

alpha1R_itns <- alpha1C_itns <- omega1R_itns <- omega1C_itns <- 
alpha2R_itns <- alpha2C_itns <- omega2R_itns <- omega2C_itns <-
lambda_itns <- delta_itns <- sigma_epsilon_itns <- vector(mode='list', length=(nt-nburn))

for(i in 1:(nt-nburn))
{
alpha1R_itns[[i]] <- subitns[[i]][[1]]
alpha1C_itns[[i]] <- subitns[[i]][[2]]
omega1R_itns[[i]] <- subitns[[i]][[3]]
omega1C_itns[[i]] <- subitns[[i]][[4]]

# polar components of MA(q) reciprocal roots
alpha2R_itns[[i]] <- subitns[[i]][[5]]
alpha2C_itns[[i]] <- subitns[[i]][[6]]
omega2R_itns[[i]] <- subitns[[i]][[7]]
omega2C_itns[[i]] <- subitns[[i]][[8]]

# Gegenbauer parameters
lambda_itns[[i]] <- subitns[[i]][[9]]
delta_itns[[i]] <- subitns[[i]][[10]]
sigma_epsilon_itns[[i]] <- subitns[[i]][[11]]
}


param_itns <- list(alpha1R_itns,alpha1C_itns,
                   omega1R_itns,omega1C_itns,
                   alpha2R_itns,alpha2C_itns,
                   omega2R_itns,omega2C_itns,
                   lambda_itns,delta_itns,
                   sigma_epsilon_itns)
param_names <- c("alpha1R","alpha1C","omega1R","omega1C",
                 "alpha2R","alpha2C","omega2R","omega2C",
                 "lambda","delta","sigma_epsilon")
# both param_itns and param_names have length 11

# Output the posterior mean and standard deviation of the parameters 
# following the discarding of the burn-in
cat("Posterior summary estimates for each model: ", "\n") 
cat("\n")
cat("parameter", "mean","( SD )", "\n")

# initialise entries of vector of parameter entries for SDF plotting
param_est <- param

for (i in 1:length(param_itns))
{
  # convert to matrix for taking the mean and sd
  # rows are nt iterations, columns is the number of sub-parameters
  param_itns_mat <- do.call(rbind,param_itns[[i]])
  # initialize vector of mean and sd - length is the number of
  # sub-parameters (e.g, R_p for alpha1R_itns)
  param_itns_mean <- param_itns_sd <- rep(0,ncol(param_itns_mat))
  for (j in 1:ncol(param_itns_mat))
  {
    # take mean and sd of each column (i.e. of each sub-parameter
    # over all iterations)
    param_itns_mean[j] <- mean(param_itns_mat[,j])
    param_itns_sd[j] <- sd(param_itns_mat[,j])
    
    # update entries of vector of parameter entries for SDF plotting
    param_est[[i]][j] <- param_itns_mean[j]
    # param_est[[i]][j] <- median(param_itns_mat[,j])
    # choosing the median produces very different results
    
    cat(param_names[i],j,": ", param_itns_mean[j],
        " (", param_itns_sd[j], ")", "\n")
    cat("\n")
  }
}

# Output the sample from posterior distribution
return(c(param_itns,param_est))
}
```

## Function for performing single-update MH algorithm

Based on pp 383 / King
```{r}
updateparam <- function(nparam,param,y,likhood,
                        lb,ub,sr,sigma_norm,Rp,Cp,Rq,Cq,k)
{
for (j in 1:nparam) # loop over each set of parameters in the list
{
  for (i in 1:length(param[[j]])) # loop over parameters in these vectors
  {
    # Keep a record of the current parameter value being updated
    oldparam <- param[[j]][i]
    # Propose a new value using a random walk from normal proposal
    param[[j]][i] <- rnorm(1, param[[j]][i], sigma_norm)
    # If proposed value for the i-th parameter is in its given range 
    # calculate acceptable probability
    if (lb[j]<=param[[j]][i] & param[[j]][i]<=ub[j])
    {
      newlikhood <- W_l(y,
                      c(param[[1]],param[[2]]), #alpha1 
                      c(param[[3]],param[[4]]), #omega1
                      c(param[[5]],param[[6]]), #alpha2
                      c(param[[7]],param[[8]]), #omega2
                      param[[9]], param[[10]], # lambda, delta
                      param[[11]], # sigma_epsilon
                      Rp,Cp,Rq,Cq,k)
      #recall that 
      #param=c(alpha1,omega1, alpha2, omega2,
      #       lambda,delta,sigma_epsilon)
    
    
      # In acceptance probability include likelihood and prior contributions
      # (proposal contributions cancel since it is a symmetric distribution)
      # build the Metropolis fraction, but on the log scale
      # Here we multiply (add on log scale) the likelihood 
      # by the priors, which are uniform for all parameters, 
      # except for the last one (sigma_epsilon), which is InvGamma
    
      # update with InvGamma prior for new sigma_epsilon
      if (j==nparam)
      {
        num <- newlikhood + log(dinvgamma(param[[j]][i],shape=sr[1],rate=sr[2],log=FALSE))
        den <- likhood + log(dinvgamma(oldparam,shape=sr[1],rate=sr[2],log=FALSE))
      }
      # update with Uniform prior for alphas, omegas, lambdas, deltas
      # (also deals with the omegas for real roots, which have to 
      # stay 0, since the upper and lower bounds are equal to 0)
      else 
      {
        num <- newlikhood + log(dunif(param[[j]][i],lb[j],ub[j]))
        den <- likhood + log(dunif(oldparam,lb[j],ub[j]))
      }
      # if num>den, then A=1, and we update the likelihood (below)
      A <- min(1,exp(num-den)) 
  }
  
  else { A <- 0 }
  
  # Simulate a random number in [0,1] 
  # and accept move with probability A;
  # else reject move and return parameter value to previous value
  u <- runif(1)
  if (u <= A) { likhood <- newlikhood } 
  else { param[[j]][i] <- oldparam }
  # rebuild the list of vectors param
  }
}
# Set the values to be output from the function to be the
# parameter values and log-likelihood value. Then output the values.
output <- c(param, likhood)
output
}
```


## Inputs
```{r}
# good values for (Rp,Cp,Rq,Cq,k): (1,1,1,1,3), 
# AR(p) model specification
Rp=1 
Cp=1 
p=Rp+2*Cp
# MA(q) model specification
Rq=1
Cq=1
q=Rq+2*Cq
# Gegenbauer(k) model specification
k=3
# Calculation of Fourier frequencies for given TS
f = fourier_freqs(y)
cat("Model specified: GARMA (",p,",",k,",",q,")", "\n")
cat("Number of parameters to estimate: ",2*(Rp+Cp+Rq+Cq+k)+1)
```

## Output 

Note:

The code is still waaaay too slow, takes about 1 minute for 100 iterations (I would need to run at least about 10000 in this time). However, the convergence is fast, with pretty smooth SDFs even after 100 iterations with 5 burn-in. Investigate whether I can vectorize some "for" loops.

```{r}
# number of simulations and burn-ins
nt = 100
nburn = 5 #if nburn is too high relative to nt, we get weird results
# this seems to be very sensitive to the burn-in, 
# but this should not be the case (maybe the sample is too small and symptotic results don't hold yet)
ptm <- proc.time()
sim_v3 <- MCMC_v3(y,Rp,Cp,Rq,Cq,k,nt,nburn)
proc.time() - ptm
```

## Histograms for parameters
```{r, iclude=FALSE, echo=FALSE}
param_itns <- sim_v3[1:11]
param_names <- c("alpha1R","alpha1C","omega1R","omega1C",
                 "alpha2R","alpha2C","omega2R","omega2C",
                 "lambda","delta","sigma_epsilon")
for (i in 1:11)
{
  # convert to matrix for taking the mean and sd
  # rows are nt iterations, columns is the number of sub-parameters
  param_itns_mat <- do.call(rbind,param_itns[[i]])
  for (j in 1:ncol(param_itns_mat))
  {
    hist(param_itns_mat[,j],
         probability = T,
         main=paste0("Histogram of ",param_names[i],j),
         xlab = "value",
         breaks = 30,
         col="gray")
  }
}
```

## Collect parameters for plotting
```{r}
param_MC_est <- sim_v3[12:22]

alpha1R_MC_est <- param_MC_est[[1]]
alpha1C_MC_est <- param_MC_est[[2]]
alpha1_MC_est <- c(alpha1R_MC_est,alpha1C_MC_est)

omega1R_MC_est <- param_MC_est[[3]]
omega1C_MC_est <- param_MC_est[[4]]
omega1_MC_est <- c(omega1R_MC_est,omega1C_MC_est)

alpha2R_MC_est <- param_MC_est[[5]]
alpha2C_MC_est <- param_MC_est[[6]]
alpha2_MC_est <- c(alpha2R_MC_est,alpha2C_MC_est)

omega2R_MC_est <- param_MC_est[[7]]
omega2C_MC_est <- param_MC_est[[8]]
omega2_MC_est <- c(omega2R_MC_est,omega2C_MC_est)

lambda_MC_est <- param_MC_est[[9]]
delta_MC_est <- param_MC_est[[10]]

sigma_epsilon_MC_est <- param_MC_est[[11]]
```

## SDF plot with locations of periodogram peaks
```{r}
SDF_MC_vals<-S_Y_vec(f,
                     alpha1_MC_est,omega1_MC_est,
                     alpha2_MC_est,omega2_MC_est,
                     lambda_MC_est,delta_MC_est,
                     sigma_epsilon_MC_est,p,q,k)

scaling_MC=max(S_p_vec(f,y))/max(SDF_MC_vals)
plot(f,S_p_vec(f,y),type = "h", lwd=2)
lines(f,scaling_MC*SDF_MC_vals,type="l",lwd=2,col="blue")
abline(v=0.1666,col="red",lty=2)
abline(v=0.084,col="red",lty=2)
abline(v=0.252,col="red",lty=2)
abline(v=0.333,col="red",lty=2)
abline(v=0.416,col="red",lty=2)
```
Notes:

- choosing the median instead of the mean as the point estimate pfor the parameters produces significantly different results.

- the algorithm seems to be very sensitive to the burn-in size (e.g. for 100 iterations with burn-in  5 the model identidies correctly the main peak, whereas for burn-in 10, it identifies the second peak as being larger), although in general the burn-in should not matter much. This may be because the number of iterations is too small and asymptotic results don't hold yet, and any removal of iterations may affect the results drastically, e.g. taking a burn-in of 11 may again produce similar results to the burn-in of 5, but not of 10.


-------------------------------------------------------

# 5. RJMCMC



-------------------------------------------------------

# 6. MLE

## Function to optimize
```{r}
# create loglikelihood evaluated at the data for the specified model
# (in order to remove the arguments y,Rp,Cp,Rq,Cq 
# for the maximization)
l <- function(param)
{
  return (-W_l(y,
               param[1:(Rp+Cp)], # alpha1
               param[(Rp+Cp+1):2*(Rp+Cp)], # omega1 
               param[(2*(Rp+Cp)+1):(2*(Rp+Cp)+Rq+Cq)], # alpha2
               param[(2*(Rp+Cp)+Rq+Cq+1):(2*(Rp+Cp+Rq+Cq))],# omega2
               param[(2*(Rp+Cp+Rq+Cq)+1):(2*(Rp+Cp+Rq+Cq)+k)], # lambda
               param[(2*(Rp+Cp+Rq+Cq)+k+1):(2*(Rp+Cp+Rq+Cq+k))], # delta
               param[(2*(Rp+Cp+Rq+Cq+k)+1)],
               Rp,Cp,Rq,Cq,k)) # sigma_epsilon
}

```

## Inputs - same as for MCMC
```{r}
Rp=1
Cp=1
p=Rp+2*Cp
Rq=1
Cq=1
q=Rq+2*Cq
k=3
f = fourier_freqs(y)
cat("Model specified: GARMA (",p,",",k,",",q,")", "\n") 
```


## Optimization
```{r}
# using nloptr (interface to C++)
# small quantity epsilon to create open intervals
# e.g. (0,1/2) would be c(0+eps,1/2-eps)
eps = 1e-05
set.seed(100)
l_max = nloptr(x0=c(runif(Rp+Cp,0,1), # alpha1R and alpha1C
                    rep(0,Rp), # omega1R
                    runif(Cp,0,1/2), # omega1C
                    runif(Rq+Cq,0,1), # alpha2R and alpha2C
                    rep(0,Rq), # omega2R
                    runif(Cq,0,1/2), # omega2C
                    runif(k,-1,1), # lambda
                    runif(k,0,1/2), # delta
                    1.5), # sigma_epsilon
               eval_f=l, 
               lb=c(rep(0+eps,Rp+Cp), # alpha1R and alpha1C
                    rep(0,Rp), # omega1R
                    rep(0+eps,Cp), # omega1C
                    rep(0+eps,Rq+Cq), # alpha2R and alpha2C
                    rep(0,Rq), # omega2R
                    rep(0+eps,Cq), # omega2C
                    rep(-1+eps,k), # lambda
                    rep(0+eps,k), # delta
                    0+eps), # sigma_epsilon
               ub=c(rep(1-eps,Rp+Cp), # alpha1R and alpha1C
                    rep(0,Rp), # omega1R
                    rep(1/2-eps,Cp), # omega1C
                    rep(1-eps,Rq+Cq), # alpha2R and alpha2C
                    rep(0,Rq), # omega2R
                    rep(1/2-eps,Cq), # omega2C
                    rep(1-eps,k), # lambda
                    rep(1/2-eps,k), # delta
                    100), # sigma_epsilon
               opts=list("algorithm"="NLOPT_LN_COBYLA", "xtol_rel"=1.0e-8))
# also, would also need to make it estimate Rp, Cp, Rq, Cq, k

```

```{r}
# estimates from optimization
param_ML_est = l_max$solution

alpha1R_ML_est = param_ML_est[1:Rp]
alpha1C_ML_est = param_ML_est[(Rp+1):(Rp+Cp)]
alpha1_ML_est = c(alpha1R_ML_est,alpha1C_ML_est)

omega1R_ML_est = param_ML_est[(Rp+Cp+1):(2*Rp+Cp)]
omega1C_ML_est = param_ML_est[(2*Rp+Cp+1):(2*(Rp+Cp))]
omega1_ML_est = c(omega1R_ML_est,omega1C_ML_est)

alpha2R_ML_est = param_ML_est[(2*(Rp+Cp)+1):(2*(Rp+Cp)+Rq)]
alpha2C_ML_est = param_ML_est[(2*(Rp+Cp)+Rq+1):(2*(Rp+Cp)+Rq+Cq)]
alpha2_ML_est = c(alpha2R_ML_est,alpha2C_ML_est)

omega2R_ML_est = param_ML_est[(2*(Rp+Cp)+Rq+Cq+1):(2*(Rp+Cp+Rq)+Cq)]
omega2C_ML_est = param_ML_est[(2*(Rp+Cp+Rq)+Cq+1):(2*(Rp+Cp+Rq+Cq))]
omega2_ML_est = c(omega2R_ML_est,omega2C_ML_est)

lambda_ML_est = param_ML_est[(2*(Rp+Cp+Rq+Cq)+1):(2*(Rp+Cp+Rq+Cq)+k)]
delta_ML_est = param_ML_est[(2*(Rp+Cp+Rq+Cq)+k+1):(2*(Rp+Cp+Rq+Cq+k))]
sigma_epsilon_ML_est = param_ML_est[(2*(Rp+Cp+Rq+Cq+k)+1)]

# regroup the estimates into a list for printing
param_ML_est = list(alpha1R_ML_est,alpha1C_ML_est,
                    omega1R_ML_est,omega1C_ML_est,
                    alpha2R_ML_est,alpha2C_ML_est,
                    omega2R_ML_est,omega2C_ML_est,
                    lambda_ML_est,delta_ML_est,
                    sigma_epsilon_ML_est)

# print
for (i in 1:11)
{
  for (j in 1:length(param_ML_est[[i]]))
  {
    cat(param_names[i],j,": ", param_ML_est[[i]][j], "\n")
    cat("\n")
  }
}
```

### SDF plot with locations of periodogram peaks
```{r}
SDF_ML_vals<-S_Y_vec(f,
                     alpha1_ML_est,omega1_ML_est,
                     alpha2_ML_est,omega2_ML_est,
                     lambda_ML_est,delta_ML_est,
                     sigma_epsilon_ML_est,p,q,k)

scaling_ML=max(S_p_vec(f,y))/max(SDF_ML_vals)
plot(f,S_p_vec(f,y),type = "h", lwd=2)
lines(f,scaling_ML*SDF_ML_vals,type="l",lwd=2,col="blue")
abline(v=0.1666,col="red",lty=2)
abline(v=0.084,col="red",lty=2)
abline(v=0.252,col="red",lty=2)
abline(v=0.333,col="red",lty=2)
abline(v=0.416,col="red",lty=2)
```
Note: SDF looks different to (worse fit than) the SDF obtained based on MCMC estimates. It does, nonetheless, capture the main peak.